{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/documents/dl_final/dl-final-project\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "hidden_size = 1024\n",
    "\n",
    "unlabeled_epochs = 1\n",
    "labeled_epochs = 1\n",
    "\n",
    "variational = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from data import get_unlabeled_set, get_labeled_set, set_seeds, make_bounding_box_images, tensor_to_image\n",
    "from model.resnet import Prototype\n",
    "\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds()\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Index: 128\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    batch_size *= torch.cuda.device_count()\n",
    "\n",
    "_, unlabeled_trainloader = get_unlabeled_set(batch_size=batch_size)\n",
    "(_, labeled_trainloader), (_, labeled_testloader) = get_labeled_set(batch_size=batch_size, validation=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from helpers.helper import draw_box\n",
    "# # The center of image is 400 * 400\n",
    "# fig, ax = plt.subplots()\n",
    "# color_list = ['b', 'g', 'orange', 'c', 'm', 'y', 'k', 'w', 'r']\n",
    "# ax.imshow(road_image[0], cmap ='binary');\n",
    "# # The ego car position\n",
    "# ax.plot(400, 400, 'x', color=\"red\")\n",
    "# for i, bb in enumerate(target[0]['bounding_box']):\n",
    "#     # You can check the implementation of the draw box to understand how it works\n",
    "#     draw_box(ax, bb, color=color_list[target[0]['category'][i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Prototype(device, hidden_dim=hidden_size, variational=variational)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    assert batch_size >= torch.cuda.device_count()\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unlabeled Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = model.module.var_loss_function\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 | 0 / 5009 ] loss: 484219.8125 curr time mins: 0.05\n",
      "loss 239305.734375\n",
      "Unlabeled Training Took (Min): 0.52\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "start_time = perf_counter()\n",
    "for epoch in range(unlabeled_epochs):\n",
    "    loss = 0.0\n",
    "    \n",
    "    max_batches = len(unlabeled_trainloader)\n",
    "    for idx, (images, camera_index) in enumerate(unlabeled_trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        images = images.to(device)\n",
    "        reconstructions, mu, logvar = model(images, mode='single-image')\n",
    "        loss, mse, kld = criterion(reconstructions, images, mu, logvar, 'single-image',\n",
    "                                  loss_reduction='sum')\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Training Wheels\n",
    "        if idx != 0 and idx % 100 == 0:\n",
    "            print('loss', loss.item())\n",
    "            break\n",
    "\n",
    "        if idx % 1000 == 0:\n",
    "            print('[', epoch, '|', idx ,'/', max_batches, ']', 'loss:', loss.item(),\n",
    "                 'curr time mins:', round(int(perf_counter() - start_time) / 60, 2))\n",
    "            \n",
    "#     model.save(file_prefix='unlabeled-')\n",
    "    \n",
    "print('Unlabeled Training Took (Min):', round(int(perf_counter() - start_time) / 60, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeled Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 | 0 / 174 ] loss: 1355311.625 curr time mins: 0.25\n",
      "[ 0 | 50 / 174 ] loss: 757768.75 curr time mins: 2.42\n",
      "[ 0 | 100 / 174 ] loss: 780738.5 curr time mins: 4.57\n",
      "[ 0 | 150 / 174 ] loss: 854315.6875 curr time mins: 6.72\n",
      "Labeled Training Took (Min): 7.88\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "start_time = perf_counter()\n",
    "for epoch in range(labeled_epochs):\n",
    "    loss = 0.0\n",
    "    \n",
    "    max_batches = len(labeled_trainloader)\n",
    "    for idx, (images, targets, _) in enumerate(labeled_trainloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        images = torch.stack(images).to(device)\n",
    "        \n",
    "        # Rasterize bounding box images for reconstruction\n",
    "        targets = make_bounding_box_images(targets)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # print('input shape:', images.shape)\n",
    "        # print('targt shape:', targets.shape)\n",
    "        \n",
    "        reconstructions, mu, logvar = model(images, mode='object-map')\n",
    "        \n",
    "        # print('outpt shape:', reconstructions.shape)\n",
    "        \n",
    "        loss, ce, kld = criterion(reconstructions, targets, mu, logvar, 'object-map', \n",
    "                                  loss_reduction='sum')\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Training Wheels\n",
    "        #print('loss', loss.item())\n",
    "        #break\n",
    "        \n",
    "        if idx % 50 == 0:\n",
    "            print('[', epoch, '|', idx ,'/', max_batches, ']', 'loss:', loss.item(),\n",
    "                 'curr time mins:', round(int(perf_counter() - start_time) / 60, 2))\n",
    "            \n",
    "    Prototype.save(model, file_prefix='labeled-test-', using_dataparallel=True, epoch_num=1)\n",
    "    \n",
    "print('Labeled Training Took (Min):', round(int(perf_counter() - start_time) / 60, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prototype(\n",
       "  (backbone): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (fc_translation_layer): Linear(in_features=512, out_features=1024, bias=True)\n",
       "  (fc1_var_encode): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc2_var_encode): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc3_var_decode): Linear(in_features=512, out_features=1024, bias=True)\n",
       "  (single_image_reconstructor): Sequential(\n",
       "    (0): UnFlatten()\n",
       "    (1): Interpolate()\n",
       "    (2): Conv2d(1024, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): ReLU()\n",
       "    (5): Interpolate()\n",
       "    (6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Interpolate()\n",
       "    (10): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 0))\n",
       "    (11): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU()\n",
       "    (13): Interpolate()\n",
       "    (14): Conv2d(32, 3, kernel_size=(3, 5), stride=(1, 1), padding=(1, 0))\n",
       "  )\n",
       "  (object_map_reconstructor): Sequential(\n",
       "    (0): UnFlatten()\n",
       "    (1): Interpolate()\n",
       "    (2): Conv2d(6144, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): ReLU()\n",
       "    (5): Interpolate()\n",
       "    (6): Conv2d(1536, 384, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Interpolate()\n",
       "    (10): Conv2d(384, 96, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU()\n",
       "    (13): Interpolate()\n",
       "    (14): Conv2d(96, 24, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU()\n",
       "    (17): Interpolate()\n",
       "    (18): Conv2d(24, 12, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n",
       "    (19): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU()\n",
       "    (21): Conv2d(12, 3, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n",
       "    (22): Interpolate()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = 'cuda'\n",
    "# d = torch.load('resnet_weights/labeled-test-resnet-1-epochs.torch', \n",
    "#            map_location=torch.device('cpu'))\n",
    "\n",
    "# model = Prototype(device)\n",
    "# model.load_state_dict(d)\n",
    "# model.to(device)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Index: 128\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 48676.453125 ce 48672.7265625 kld 3.728271007537842\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 56036.83203125 ce 56033.84375 kld 2.9869470596313477\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 66200.0859375 ce 65725.890625 kld 474.1986083984375\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 56355.65625 ce 56353.046875 kld 2.6100611686706543\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 48736.5546875 ce 48733.91796875 kld 2.638319492340088\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 51912.83203125 ce 51909.078125 kld 3.7555336952209473\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 64188.56640625 ce 64177.67578125 kld 10.892200469970703\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 64177.78515625 ce 64168.56640625 kld 9.21791934967041\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 68914.6875 ce 68911.2734375 kld 3.4131081104278564\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 66477.78125 ce 66475.0625 kld 2.7205452919006348\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 58209.16015625 ce 58206.50390625 kld 2.6546497344970703\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 59308.8359375 ce 59306.25390625 kld 2.580151081085205\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 73170.171875 ce 72808.1328125 kld 362.04296875\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 58916.5078125 ce 58911.6875 kld 4.82161283493042\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 50620.48828125 ce 50617.34765625 kld 3.142364978790283\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 55367.04296875 ce 55363.1171875 kld 3.9239425659179688\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 52850.17578125 ce 52811.8515625 kld 38.3237190246582\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 69316.328125 ce 68835.3046875 kld 481.0206604003906\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 63411.7109375 ce 63290.65234375 kld 121.0579833984375\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 67506.9921875 ce 67027.453125 kld 479.542236328125\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 64354.8984375 ce 64343.96875 kld 10.929603576660156\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 66366.4453125 ce 65874.125 kld 492.3233337402344\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 61504.56640625 ce 61088.6875 kld 415.8777770996094\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 65611.421875 ce 65603.328125 kld 8.09075927734375\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 57900.64453125 ce 57898.01953125 kld 2.6255383491516113\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 54186.96484375 ce 54183.9921875 kld 2.972367525100708\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 65270.46875 ce 65262.5546875 kld 7.915113925933838\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 64283.68359375 ce 64273.05078125 kld 10.633066177368164\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 65562.2421875 ce 65554.0703125 kld 8.16801643371582\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 53519.59765625 ce 53516.55078125 kld 3.0453226566314697\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 64531.4296875 ce 64523.8984375 kld 7.531264305114746\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 76489.046875 ce 76267.6796875 kld 221.3679656982422\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 75409.234375 ce 75179.15625 kld 230.07615661621094\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 63402.60546875 ce 63391.66796875 kld 10.93836498260498\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 58815.6171875 ce 58810.296875 kld 5.318605422973633\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 63651.984375 ce 63644.5078125 kld 7.4782915115356445\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 79058.8046875 ce 78983.203125 kld 75.60208129882812\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 50823.1171875 ce 50820.5859375 kld 2.5325989723205566\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 68635.625 ce 68632.8828125 kld 2.740780830383301\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 63631.99609375 ce 63623.34765625 kld 8.64764404296875\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 58482.57421875 ce 58479.8046875 kld 2.771202802658081\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 72111.1640625 ce 71744.734375 kld 366.43060302734375\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 72983.734375 ce 72537.71875 kld 446.0164489746094\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 66603.09375 ce 66594.8671875 kld 8.22458553314209\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 64064.26171875 ce 64053.5546875 kld 10.705804824829102\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 49313.390625 ce 49309.91015625 kld 3.4791300296783447\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 50737.046875 ce 50733.3203125 kld 3.727774143218994\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 61678.72265625 ce 61674.98046875 kld 3.7413692474365234\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 48771.60546875 ce 48768.95703125 kld 2.647867441177368\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 59688.765625 ce 59685.1796875 kld 3.585622787475586\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 59877.23828125 ce 59873.55859375 kld 3.6814396381378174\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 49734.58984375 ce 49730.88671875 kld 3.7045297622680664\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 51903.0625 ce 51900.19140625 kld 2.870466470718384\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 76167.4140625 ce 75973.109375 kld 194.30445861816406\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 54307.5078125 ce 54304.8984375 kld 2.6091604232788086\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 53083.0 ce 53080.2890625 kld 2.7102112770080566\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 62497.8046875 ce 62490.625 kld 7.17798376083374\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 52484.56640625 ce 52481.8203125 kld 2.745957851409912\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 48761.01171875 ce 48758.00390625 kld 3.0074045658111572\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 45485.97265625 ce 45483.3671875 kld 2.604437828063965\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 55617.34765625 ce 55614.94921875 kld 2.3980531692504883\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 59471.18359375 ce 59466.55078125 kld 4.632793426513672\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 67837.7734375 ce 67834.90625 kld 2.867774724960327\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 54808.62109375 ce 54804.859375 kld 3.7610621452331543\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 57674.65234375 ce 57672.171875 kld 2.4785256385803223\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 47772.86328125 ce 47770.04296875 kld 2.820378303527832\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 49121.97265625 ce 49118.2421875 kld 3.732069730758667\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n",
      "torch.Size([1, 800, 800])\n",
      "loss 58196.3671875 ce 58193.2265625 kld 3.1411209106445312\n",
      "[0]\n",
      "torch.Size([1, 6, 3, 256, 306])\n",
      "torch.Size([1, 800, 800])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-4b4ca0380440>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mimg_recon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'object-map'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mimg_recon_sm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_recon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_recon_sm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/documents/dl_final/dl-final-project/model/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mode)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'object-map'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_variational\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_map_variational_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_map_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/documents/dl_final/dl-final-project/model/resnet.py\u001b[0m in \u001b[0;36mobject_map_variational_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# NOTE: Is this correct to do this?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         fc_latent_translation = nn.Linear(z_acc.size(1),\n\u001b[0;32m--> 221\u001b[0;31m                                           self.hidden_dim * x.size(0)).to(self.device)\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0mz_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc_latent_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, bias)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mreset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mfan_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_fan_in_and_fan_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/init.py\u001b[0m in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstd\u001b[0m  \u001b[0;31m# Calculate uniform bounds from standard deviation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "(_, labeled_trainloader), (_, labeled_testloader) = get_labeled_set(batch_size=1, validation=0.2)\n",
    "for (images, targets, _) in labeled_testloader:\n",
    "    \n",
    "    images = torch.stack(images).to(device)\n",
    "    targets = make_bounding_box_images(targets).to(device)\n",
    "\n",
    "    print(images.shape)\n",
    "    print(targets.shape)\n",
    "    \n",
    "    img_recon, mu, logvar = model(images, mode='object-map')\n",
    "    img_recon_sm = torch.argmax(torch.softmax(img_recon, 1), 1)\n",
    "    print(img_recon_sm.shape)\n",
    "    loss, ce, kld = criterion(img_recon, targets, mu, logvar, 'object-map', \n",
    "                                  loss_reduction='sum')\n",
    "    \n",
    "    print('loss', loss.item(), 'ce', ce.item(), 'kld', kld.item())\n",
    "    print(np.unique(img_recon_sm.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
